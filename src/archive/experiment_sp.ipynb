{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from captum.attr import Occlusion\n",
    "from copy import deepcopy\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# utils\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import network\n",
    "from datasets import SegmentationDataset\n",
    "\n",
    "save_path = \"../maps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_superpixel_occlusion_map(model, input_image, mask=None, superpixel_list=None):\n",
    "    \"\"\"\n",
    "    Generate an occlusion map for a given image input using superpixel groupings for occlusion.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): Pre-trained segmentation model.\n",
    "    - input_image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
    "    - mask (torch.Tensor): Mask of shape (H, W), with 1s for pixels to analyze, 0s elsewhere.\n",
    "    - superpixel_list (np.array): Matrix of shape (H, W), where each element is a group number \n",
    "      indicating the superpixel assignment of that pixel.\n",
    "    \n",
    "    Returns:\n",
    "    - occlusion_map (np.array): Heatmap of occlusion influence for the masked region.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure input image and model are on the same device\n",
    "    input_image = input_image.to(device).unsqueeze(0)  # add batch dimension\n",
    "    original_pred = model(input_image).squeeze(0)  # model prediction on original image\n",
    "    original_pred = original_pred.cpu().detach().numpy()\n",
    "    original_masked_pred = original_pred * mask  # Apply mask to the output\n",
    "\n",
    "    # Initialize occlusion map\n",
    "    occlusion_map = np.zeros(input_image.shape[2:])\n",
    "\n",
    "    # Identify unique superpixel groups\n",
    "    unique_groups = np.unique(superpixel_list)\n",
    "\n",
    "    # Iterate over each unique superpixel group\n",
    "    for group in tqdm(unique_groups):\n",
    "        # Clone and occlude the superpixel region in the input image\n",
    "        occluded_image = deepcopy(input_image)\n",
    "        occluded_mask = (superpixel_list == group)\n",
    "        occluded_image[:, :, occluded_mask] = 0  # occlude with zeros\n",
    "\n",
    "        # Get prediction for the occluded image\n",
    "        with torch.no_grad():\n",
    "            occluded_pred = model(occluded_image).squeeze(0)\n",
    "            occluded_pred = occluded_pred.cpu().detach().numpy()\n",
    "\n",
    "        # Calculate difference in predictions for the masked region\n",
    "        occlusion_influence = np.abs(original_masked_pred - (occluded_pred * mask)).sum().item()\n",
    "        occlusion_map[occluded_mask] += occlusion_influence\n",
    "\n",
    "    # Normalize occlusion map to [0, 1]\n",
    "    occlusion_map = (occlusion_map - np.min(occlusion_map)) / (np.max(occlusion_map) - np.min(occlusion_map))\n",
    "\n",
    "    return occlusion_map\n",
    "\n",
    "def plot_occlusion_map(bands, occlusion_map):\n",
    "    # Plotting the occlusion map\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    nir = bands[3].cpu().detach().numpy()\n",
    "    plt.imshow(nir, cmap='gray', alpha=0.5)\n",
    "    plt.imshow(occlusion_map, cmap='hot', alpha=0.6)\n",
    "    plt.colorbar(label=\"Influence Score\")\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "\n",
    "def get_segments(input_image, method='slic', **kwargs):\n",
    "    # Copy the input image to avoid modifying the original\n",
    "    img = input_image.copy()\n",
    "\n",
    "    # Define a dictionary to map method names to their respective function calls\n",
    "    segmentation_methods = {\n",
    "        'felzenszwalb': lambda: felzenszwalb(img, **kwargs),\n",
    "        'slic': lambda: slic(img, **kwargs),\n",
    "        'quickshift': lambda: quickshift(img, **kwargs),\n",
    "        'watershed': lambda: watershed(sobel(rgb2gray(img)), **kwargs),\n",
    "    }\n",
    "\n",
    "    # Validate the method\n",
    "    if method not in segmentation_methods:\n",
    "        raise ValueError(f\"Unsupported segmentation method: {method}. Choose from {list(segmentation_methods.keys())}.\")\n",
    "\n",
    "    # Try to execute the selected method, handle potential errors gracefully\n",
    "    try:\n",
    "        segments = segmentation_methods[method]()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred during segmentation with {method}: {str(e)}\")\n",
    "\n",
    "    return segments\n",
    "\n",
    "band_dic = {\"sentinel\":{\"coastal\":0,\"blue\":1,\"green\":2,\"red\":3,\"rededge1\":4,\"rededge2\":5,\"rededge3\":6,\"nir\":7,\"narrownir\":8,\"watervapour\":9,\"swir1\":10,\"swir2\":11},\n",
    "         \"landsat\":{\"blue\":0,\"green\":1,\"red\":2,\"nir\":3,\"swir1\":4,\"swir2\":5,\"thermal\":6}}\n",
    "\n",
    "def scale_bands(img,satellite=\"landsat\"):\n",
    "    \"\"\"Scale bands to 0-1\"\"\"\n",
    "    img = img.astype(\"float32\")\n",
    "    if satellite == \"landsat\":\n",
    "        img = np.clip(img * 0.0000275 - 0.2, 0, 1)\n",
    "    elif satellite == \"sentinel\":\n",
    "        img = np.clip(img/10000, 0, 1)\n",
    "    return img\n",
    "\n",
    "def get_rgb(img, bands=['red','green',\"blue\"],satellite ='landsat', contrast=1):\n",
    "    \"\"\"Convert a stacked array of bands to RGB\"\"\"\n",
    "\n",
    "    r = band_dic[satellite][bands[0]]\n",
    "    g = band_dic[satellite][bands[1]]\n",
    "    b = band_dic[satellite][bands[2]]\n",
    "\n",
    "    rgb = img[:,:, [r,g,b]]\n",
    "    rgb = rgb.astype(np.float32)\n",
    "    rgb = scale_bands(rgb, satellite)\n",
    "    rgb = np.clip(rgb, 0, contrast) / contrast\n",
    "\n",
    "    return rgb\n",
    "\n",
    "def enhance_contrast(img, contrast):\n",
    "    \n",
    "    \"\"\"Enhance the contrast of an image using 3 approaches:\n",
    "    - contrast = 'hist': apply histogram equalization\n",
    "    - contrast = 'luminance': apply histogram equalization to the luminance channel\n",
    "    - contrast = float: rescale the image to the specified value\"\"\"\n",
    "\n",
    "    processed_img = img.copy()\n",
    "    \n",
    "    processed_img = processed_img.astype(np.float32)\n",
    "    processed_img = np.clip(processed_img, 0, contrast) / contrast\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths\n",
    "paths = glob.glob('../../data/LICS/test/*')\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.load(paths[0])\n",
    "utils.display_bands(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset object\n",
    "lics_dataset = SegmentationDataset(paths) \n",
    "\n",
    "# Download the model directly from Hugging Face\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"a-data-odyssey/coastal-image-segmentation\", \n",
    "    filename=\"LICS_UNET_12JUL2024.pth\")\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(model_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "device = torch.device('mps' if torch.backends.mps.is_built() \n",
    "                      else 'cuda' if torch.cuda.is_available() \n",
    "                      else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first instance\n",
    "bands, target, edge = lics_dataset.__getitem__(0)\n",
    "\n",
    "# Make a prediction\n",
    "input = bands.to(device)\n",
    "input = input.unsqueeze(0)\n",
    "output = model(input)\n",
    "\n",
    "print(target.shape)\n",
    "print(output.shape)\n",
    "\n",
    "# Get the water mask \n",
    "target_water = np.argmax(target, axis=0)\n",
    "\n",
    "# Get the predicted water mask\n",
    "output = output.cpu().detach().numpy().squeeze()\n",
    "output = np.argmax(output, axis=0)\n",
    "\n",
    "# Plot the prediction\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9, 5))\n",
    "axs[0].imshow(target_water, cmap='gray')\n",
    "axs[0].set_title('Target', fontsize=16)\n",
    "\n",
    "axs[1].imshow(output, cmap='gray')\n",
    "\n",
    "accuracy = np.mean(np.array(target_water == output))\n",
    "accuracy = round(accuracy, 3)\n",
    "axs[1].set_title(f'Prediction ({accuracy})', fontsize=16)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters\n",
    "satellite='landsat'\n",
    "rgb_bands=[\"red\",\"green\",\"blue\"]\n",
    "method='slic'\n",
    "n_segments=2000\n",
    "\n",
    "all_bands_ = img.copy()\n",
    "\n",
    "# Get 3 spectral bands\n",
    "img = utils.get_rgb(np.array(bands),bands=rgb_bands,satellite=satellite)\n",
    "segments = get_segments(img,method=method, n_segments=n_segments)\n",
    "\n",
    "# Visualise process\n",
    "fig, ax = plt.subplots(1,2, figsize=(8, 5))\n",
    "\n",
    "# Enhance contrast for visualisation\n",
    "img_processed = enhance_contrast(img,0.2)\n",
    "ax[0].imshow(img_processed)\n",
    "ax[0].set_title('Spectral Bands')\n",
    "\n",
    "ax[1].imshow(utils.mark_boundaries(img_processed, segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first instance\n",
    "bands, target, edge = lics_dataset.__getitem__(0)\n",
    "\n",
    "# Shape of the image\n",
    "print(bands.shape)\n",
    "print(target.shape)\n",
    "print(edge.shape)\n",
    "\n",
    "# visualise the image\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "rgb = utils.get_rgb(np.array(bands),contrast=0.3)\n",
    "segments = get_segments(rgb,method=method, n_segments=n_segments)\n",
    "\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target[1], cmap='gray')\n",
    "ax[2].imshow(edge, cmap='gray')\n",
    "\n",
    "ax[3].imshow(utils.mark_boundaries(img_processed, segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_pixel = np.zeros_like(target[1])\n",
    "land_pixel[50, 50] = 1\n",
    "land_pixel[150, 5] = 1\n",
    "land_pixel[130, 150] = 1\n",
    "\n",
    "water_pixel = np.zeros_like(target[1])\n",
    "water_pixel[200, 200] = 1\n",
    "water_pixel[100,150] = 1\n",
    "water_pixel[200,50] = 1\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].imshow(land_pixel,cmap='gray')\n",
    "ax[1].imshow(water_pixel,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "bands, target, edge = lics_dataset.__getitem__(i)\n",
    "rgb = utils.get_rgb(np.array(bands),contrast=0.3)\n",
    "\n",
    "n_segments = 2000\n",
    "segments = get_segments(rgb,method=method, n_segments=n_segments)\n",
    "\n",
    "# Generate occlusion maps\n",
    "water_map = generate_superpixel_occlusion_map(model, bands, water_pixel,segments)\n",
    "np.save(save_path + f\"water_map_{i}_{n_segments}.npy\", water_map)\n",
    "\n",
    "land_map = generate_superpixel_occlusion_map(model, bands, land_pixel,segments)\n",
    "np.save(save_path + f\"land_map_{i}_{n_segments}.npy\", land_map)\n",
    "\n",
    "mask = edge.cpu().detach().numpy()\n",
    "coasline_map = generate_superpixel_occlusion_map(model, bands, mask,segments)\n",
    "np.save(save_path + f\"coastline_map_{i}_{n_segments}.npy\", coasline_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n_segments = 2000\n",
    "water_map = np.load(save_path + f\"water_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, water_map)\n",
    "\n",
    "land_map = np.load(save_path + f\"land_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, land_map)\n",
    "\n",
    "coasline_map = np.load(save_path + f\"coastline_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, coasline_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first instance\n",
    "bands, target, edge = lics_dataset.__getitem__(3)\n",
    "\n",
    "# Shape of the image\n",
    "print(bands.shape)\n",
    "print(target.shape)\n",
    "print(edge.shape)\n",
    "\n",
    "# visualise the image\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "rgb = utils.get_rgb(np.array(bands),contrast=0.3)\n",
    "segments = get_segments(rgb,method=method, n_segments=n_segments)\n",
    "\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target[1], cmap='gray')\n",
    "ax[2].imshow(edge, cmap='gray')\n",
    "\n",
    "ax[3].imshow(utils.mark_boundaries(img_processed, segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_pixel = np.zeros_like(target[1])\n",
    "#land_pixel = np.copy(edge)\n",
    "land_pixel[230, 50] = 1\n",
    "land_pixel[230, 200] = 1\n",
    "land_pixel[50, 50] = 1\n",
    "\n",
    "water_pixel = np.zeros_like(target[1])\n",
    "water_pixel[50, 200] = 1\n",
    "water_pixel[150,120] = 1\n",
    "water_pixel[210,50] = 1\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].imshow(land_pixel,cmap='gray')\n",
    "ax[1].imshow(water_pixel,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "bands, target, edge = lics_dataset.__getitem__(i)\n",
    "rgb = utils.get_rgb(np.array(bands),contrast=0.3)\n",
    "\n",
    "n_segments = 2000\n",
    "segments = get_segments(rgb,method=method, n_segments=n_segments)\n",
    "\n",
    "# Generate occlusion maps\n",
    "water_map = generate_superpixel_occlusion_map(model, bands, water_pixel,segments)\n",
    "np.save(save_path + f\"water_map_{i}_{n_segments}.npy\", water_map)\n",
    "\n",
    "land_map = generate_superpixel_occlusion_map(model, bands, land_pixel,segments)\n",
    "np.save(save_path + f\"land_map_{i}_{n_segments}.npy\", land_map)\n",
    "\n",
    "mask = edge.cpu().detach().numpy()\n",
    "coasline_map = generate_superpixel_occlusion_map(model, bands, mask,segments)\n",
    "np.save(save_path + f\"coastline_map_{i}_{n_segments}.npy\", coasline_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "n_segments = 2000\n",
    "water_map = np.load(save_path + f\"water_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, water_map)\n",
    "\n",
    "land_map = np.load(save_path + f\"land_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, land_map)\n",
    "\n",
    "coasline_map = np.load(save_path + f\"coastline_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, coasline_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first instance\n",
    "bands, target, edge = lics_dataset.__getitem__(5)\n",
    "\n",
    "# Shape of the image\n",
    "print(bands.shape)\n",
    "print(target.shape)\n",
    "print(edge.shape)\n",
    "\n",
    "# visualise the image\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "rgb = utils.get_rgb(np.array(bands),contrast=0.3)\n",
    "segments = get_segments(rgb,method=method, n_segments=n_segments)\n",
    "\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target[1], cmap='gray')\n",
    "ax[2].imshow(edge, cmap='gray')\n",
    "\n",
    "ax[3].imshow(utils.mark_boundaries(img_processed, segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_pixel = np.zeros_like(target[1])\n",
    "#land_pixel = np.copy(edge)\n",
    "land_pixel[200, 50] = 1\n",
    "land_pixel[50, 150] = 1\n",
    "land_pixel[50, 50] = 1\n",
    "\n",
    "water_pixel = np.zeros_like(target[1])\n",
    "#water_pixel = np.copy(edge)\n",
    "water_pixel[50, 200] = 1\n",
    "water_pixel[150,120] = 1\n",
    "water_pixel[200,200] = 1\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].imshow(land_pixel,cmap='gray')\n",
    "ax[1].imshow(water_pixel,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "bands, target, edge = lics_dataset.__getitem__(i)\n",
    "rgb = utils.get_rgb(np.array(bands),contrast=0.3)\n",
    "\n",
    "n_segments = 2000\n",
    "segments = get_segments(rgb,method=method, n_segments=n_segments)\n",
    "\n",
    "# Generate occlusion maps\n",
    "water_map = generate_superpixel_occlusion_map(model, bands, water_pixel,segments)\n",
    "np.save(save_path + f\"water_map_{i}_{n_segments}.npy\", water_map)\n",
    "\n",
    "land_map = generate_superpixel_occlusion_map(model, bands, land_pixel,segments)\n",
    "np.save(save_path + f\"land_map_{i}_{n_segments}.npy\", land_map)\n",
    "\n",
    "mask = edge.cpu().detach().numpy()\n",
    "coasline_map = generate_superpixel_occlusion_map(model, bands, mask,segments)\n",
    "np.save(save_path + f\"coastline_map_{i}_{n_segments}.npy\", coasline_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "n_segments = 2000\n",
    "water_map = np.load(save_path + f\"water_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, water_map)\n",
    "\n",
    "land_map = np.load(save_path + f\"land_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, land_map)\n",
    "\n",
    "coasline_map = np.load(save_path + f\"coastline_map_{i}_{n_segments}.npy\")\n",
    "plot_occlusion_map(bands, coasline_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = edge.cpu().detach().numpy()\n",
    "# Ensure input image and model are on the same device\n",
    "input_image = bands.to(device).unsqueeze(0)  # add batch dimension\n",
    "original_pred = model(input_image).squeeze(0)  # model prediction on original image\n",
    "original_pred = original_pred.cpu().detach().numpy()\n",
    "original_masked_pred = original_pred * mask  # Apply mask to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_pred.shape)\n",
    "print(original_masked_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize occlusion map\n",
    "occlusion_map = np.zeros(input_image.shape[2:])\n",
    "\n",
    "print(occlusion_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0\n",
    "x = 0\n",
    "patch_size = 10\n",
    "occluded_image = deepcopy(input_image)\n",
    "occluded_image[:, :, y:y + patch_size, x:x + patch_size] = 0  # occlude with zeros\n",
    "\n",
    "nir = occluded_image[0][3].cpu().detach().numpy()\n",
    "plt.imshow(nir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    occluded_pred = model(occluded_image).squeeze(0)\n",
    "    occluded_pred = occluded_pred.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differnece = np.abs(original_masked_pred - (occluded_pred * mask))\n",
    "occlusion_influence = differnece.sum().item()\n",
    "\n",
    "print(occluded_pred.shape)\n",
    "print(differnece.shape)\n",
    "print(occlusion_influence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over image in patches\n",
    "for y in tqdm(range(0, input_image.shape[2] - patch_size + 1, stride)):\n",
    "    for x in range(0, input_image.shape[3] - patch_size + 1, stride):\n",
    "        # Clone and occlude a patch in the input image\n",
    "        \n",
    "        # Get prediction for the occluded image\n",
    "        \n",
    "\n",
    "        # Calculate difference in predictions for the masked region\n",
    "        \n",
    "        occlusion_map[y:y + patch_size, x:x + patch_size] += occlusion_influence\n",
    "\n",
    "# Normalize occlusion map to [0, 1]\n",
    "occlusion_map = (occlusion_map - np.min(occlusion_map)) / (np.max(occlusion_map) - np.min(occlusion_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate occlusion map using Captum\n",
    "occlusion_map = generate_occlusion_map(model, bands, land_pixel,patch_size=5,stride=5)\n",
    "\n",
    "# Plotting the occlusion map\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(rgb, cmap='gray', alpha=0.5)\n",
    "plt.imshow(occlusion_map, cmap='hot', alpha=0.6)\n",
    "plt.colorbar(label=\"Influence Score\")\n",
    "plt.title(\"Occlusion Map - Influence on Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate occlusion map using Captum\n",
    "coastline = edge.cpu().detach().numpy()\n",
    "occlusion_map = generate_occlusion_map(model, bands, coastline,patch_size=5,stride=5)\n",
    "\n",
    "# Plotting the occlusion map\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(rgb, cmap='gray', alpha=0.5)\n",
    "plt.imshow(occlusion_map, cmap='hot', alpha=0.6)\n",
    "plt.colorbar(label=\"Influence Score\")\n",
    "plt.title(\"Occlusion Map - Influence on Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "\n",
    "# Load and prepare the data\n",
    "input_image, target = lics_dataset.__getitem__(0)\n",
    "mask = torch.zeros_like(target, dtype=torch.float32)\n",
    "mask[target == 1] = 1  # Example: focus on ocean pixels\n",
    "\n",
    "# Generate occlusion map for masked pixels\n",
    "occlusion_map = generate_occlusion_map(model, input_image, mask)\n",
    "\n",
    "# Plotting the occlusion map\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(to_pil_image(input_image), cmap='gray', alpha=0.5)\n",
    "plt.imshow(occlusion_map, cmap='hot', alpha=0.6)\n",
    "plt.colorbar(label=\"Influence Score\")\n",
    "plt.title(\"Occlusion Map - Influence on Predictions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import Occlusion\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "def generate_superpixel_occlusion_map(model, input_image, mask=None, n_segments=50):\n",
    "    \"\"\"\n",
    "    Generate an occlusion map using superpixels as occlusion regions.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): Pre-trained segmentation model.\n",
    "    - input_image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
    "    - mask (torch.Tensor): Mask of shape (H, W), with 1s for pixels to analyze, 0s elsewhere.\n",
    "    - n_segments (int): Number of superpixels to generate.\n",
    "    \n",
    "    Returns:\n",
    "    - occlusion_map (np.array): Heatmap of occlusion influence for the masked region.\n",
    "    \"\"\"\n",
    "    # Convert input tensor to numpy for superpixel segmentation\n",
    "    input_image_np = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Generate superpixels\n",
    "    superpixels = slic(input_image_np, n_segments=n_segments, start_label=0)\n",
    "    num_superpixels = superpixels.max() + 1\n",
    "    \n",
    "    # Initialize occlusion map\n",
    "    occlusion_map = np.zeros(superpixels.shape)\n",
    "    \n",
    "    # Define baseline as a zero image (same size as input)\n",
    "    baseline = torch.zeros_like(input_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Loop over each superpixel to occlude it\n",
    "    for sp in range(num_superpixels):\n",
    "        # Create a mask for the current superpixel\n",
    "        sp_mask = torch.tensor(superpixels == sp, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Occlude the superpixel region by setting it to the baseline\n",
    "        occluded_image = input_image.clone().unsqueeze(0).to(device)\n",
    "        occluded_image[0][:, sp_mask.bool()] = 0  # Occlude with zero baseline\n",
    "\n",
    "        # Make predictions for occluded image\n",
    "        with torch.no_grad():\n",
    "            original_pred = model(input_image.unsqueeze(0).to(device)).squeeze(0) * mask.to(device)\n",
    "            occluded_pred = model(occluded_image).squeeze(0) * mask.to(device)\n",
    "        \n",
    "        # Calculate the influence score for this superpixel\n",
    "        influence_score = torch.abs(original_pred - occluded_pred).sum().item()\n",
    "        occlusion_map[superpixels == sp] = influence_score\n",
    "    \n",
    "    # Normalize occlusion map to [0, 1]\n",
    "    occlusion_map = (occlusion_map - np.min(occlusion_map)) / (np.max(occlusion_map) - np.min(occlusion_map))\n",
    "    \n",
    "    return occlusion_map\n",
    "\n",
    "# Load and prepare the data\n",
    "input_image, target = lics_dataset.__getitem__(0)\n",
    "mask = torch.zeros_like(target, dtype=torch.float32)\n",
    "mask[target == 1] = 1  # Example: focus on ocean pixels\n",
    "\n",
    "# Generate occlusion map using superpixels\n",
    "occlusion_map = generate_superpixel_occlusion_map(model, input_image, mask)\n",
    "\n",
    "# Plotting the occlusion map with superpixel boundaries\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(label2rgb(superpixels, input_image.permute(1, 2, 0).cpu().numpy(), kind='avg'), alpha=0.5)\n",
    "plt.imshow(occlusion_map, cmap='hot', alpha=0.6)\n",
    "plt.colorbar(label=\"Influence Score\")\n",
    "plt.title(\"Superpixel Occlusion Map - Influence on Predictions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_occlusion_map(model, input_image, mask=None, sliding_window=5, stride=1):\n",
    "    \"\"\"\n",
    "    Generate an occlusion map using Captum for a given input image and mask.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): Pre-trained segmentation model.\n",
    "    - input_image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
    "    - mask (torch.Tensor): Mask of shape (H, W), with 1s for pixels to analyze, 0s elsewhere.\n",
    "    - sliding_window (int): Size of the occlusion patch.\n",
    "    - stride (int): Stride for moving the occlusion patch across the image.\n",
    "    \n",
    "    Returns:\n",
    "    - occlusion_map (np.array): Heatmap of occlusion influence for the masked region.\n",
    "    \"\"\"\n",
    "    # Ensure input image and model are on the same device\n",
    "    input_image = input_image.to(device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Initialize Captum Occlusion object\n",
    "    occlusion = Occlusion(model)\n",
    "    \n",
    "    # Generate occlusion attributions for the specified output class (0 or 1 for land or ocean)\n",
    "    attributions = occlusion.attribute(\n",
    "        input_image,\n",
    "        target=0,  # Index for land/ocean prediction, adjust as needed\n",
    "        sliding_window_shapes=(input_image.shape[1], sliding_window, sliding_window),\n",
    "        strides=(input_image.shape[1], stride, stride),\n",
    "        baselines=0\n",
    "    )\n",
    "    \n",
    "    # Convert attributions to numpy and apply mask to occlude only specified areas\n",
    "    occlusion_map = attributions.squeeze().cpu().numpy()\n",
    "    if mask is not None:\n",
    "        occlusion_map = occlusion_map * mask.cpu().numpy()\n",
    "    \n",
    "    # Normalize occlusion map to [0, 1]\n",
    "    occlusion_map = (occlusion_map - np.min(occlusion_map)) / (np.max(occlusion_map) - np.min(occlusion_map))\n",
    "    \n",
    "    return occlusion_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Occlusion",
   "language": "python",
   "name": "occlusion_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
